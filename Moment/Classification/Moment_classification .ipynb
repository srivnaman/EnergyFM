{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebd7b0a0",
   "metadata": {},
   "source": [
    "FineTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b6adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from momentfm import MOMENTPipeline\n",
    "from momentfm.data.classification_dataset import ClassificationDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from aeon.datasets import write_to_ts_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "set_seed = 42\n",
    "torch.manual_seed(set_seed)\n",
    "np.random.seed(set_seed)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*use_reentrant.*\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"./Dataset/Classification/60_min/comstock_60min_small.csv\").drop(\"Timestamp\", axis=1)\n",
    "X = df.T  \n",
    "df_label_all = pd.read_csv(\"./Dataset/Classification/60_min/comstock_60min_labels.csv\")\n",
    "appliance_names = ['cooling_ON', 'fans_ON', 'heat_rejection_ON', 'heating_ON', 'refrigeration_ON', 'water_systems_ON']\n",
    "df_label = df_label_all[appliance_names]\n",
    "y = df_label.values  \n",
    "\n",
    "results = []  # Store results per appliance\n",
    "\n",
    "for appliance in appliance_names:\n",
    "    print(f\"\\n⚡ Starting fine-tuning for appliance: {appliance}\")\n",
    "    start_time = time.time()\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "    y = df_label_all[appliance]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    X_train = np.array(X_train)[:, np.newaxis, :]\n",
    "    X_test = np.array(X_test)[:, np.newaxis, :]\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    write_to_ts_file(X_train, '/home/user/Downloads/moment/dataset/', y_train,\n",
    "                    problem_name='Comstock_TRAIN.ts', header=None, regression=False)\n",
    "\n",
    "    write_to_ts_file(X_test, '/home/user/Downloads/moment/dataset/', y_test,\n",
    "                    problem_name='Comstock_TEST.ts', header=None, regression=False)\n",
    "\n",
    "    train_dataset = ClassificationDataset(data_split='train')\n",
    "    test_dataset = ClassificationDataset(data_split='test')\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, drop_last=False)\n",
    "\n",
    "    model = MOMENTPipeline.from_pretrained(\n",
    "        \"AutonLab/MOMENT-1-large\", \n",
    "        model_kwargs={\n",
    "            'task_name': 'classification',\n",
    "            'n_channels': 1,\n",
    "            'num_class': 2,\n",
    "            'freeze_encoder': False,\n",
    "            'freeze_embedder': False,\n",
    "            'reduction': 'mean',\n",
    "        },\n",
    "    )\n",
    "    model.init()\n",
    "    model.to(device).float()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    T_MAX = max(int((700 / 168) / 32 * 10), 1)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=T_MAX, eta_min=1e-7)\n",
    "\n",
    "    best_test_acc = 0.0\n",
    "    final_metrics = {}\n",
    "\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        for batch_x, batch_masks, batch_labels in tqdm(train_loader):\n",
    "            batch_x = batch_x.to(device).float().requires_grad_()\n",
    "            batch_masks = batch_masks.to(device).long()\n",
    "            batch_labels = batch_labels.to(device).long()\n",
    "            batch_masks = torch.ones(batch_x.size(0), batch_x.size(-1)).long().to(device)\n",
    "\n",
    "            output = model(x_enc=batch_x, input_mask=batch_masks, reduction='mean')\n",
    "            logits = output.logits\n",
    "\n",
    "            loss = criterion(logits, batch_labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=5.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            correct_preds += (predicted == batch_labels).sum().item()\n",
    "            total_preds += batch_labels.size(0)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        correct_test_preds = 0\n",
    "        total_test_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_masks, batch_labels in test_loader:\n",
    "                batch_x = batch_x.to(device).float()\n",
    "                batch_masks = batch_masks.to(device).long()\n",
    "                batch_labels = batch_labels.to(device).long()\n",
    "\n",
    "                output = model(x_enc=batch_x, input_mask=batch_masks, reduction='mean')\n",
    "                logits = output.logits\n",
    "\n",
    "                _, predicted = torch.max(logits, 1)\n",
    "                correct_test_preds += (predicted == batch_labels).sum().item()\n",
    "                total_test_preds += batch_labels.size(0)\n",
    "\n",
    "                all_preds.append(predicted.cpu().numpy())\n",
    "                all_labels.append(batch_labels.cpu().numpy())\n",
    "\n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        all_labels = np.concatenate(all_labels)\n",
    "\n",
    "        test_acc = correct_test_preds / total_test_preds\n",
    "        test_prec = precision_score(all_labels, all_preds, zero_division=0)\n",
    "        test_rec = recall_score(all_labels, all_preds, zero_division=0)\n",
    "        test_f1 = f1_score(all_labels, all_preds, zero_division=0, average='macro')\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Test Acc={test_acc:.4f}, Precision={test_prec:.4f}, Recall={test_rec:.4f}, F1={test_f1:.4f}\")\n",
    "\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            final_metrics = {\n",
    "                'Appliance': appliance,\n",
    "                'Accuracy': test_acc,\n",
    "                'Precision': test_prec,\n",
    "                'Recall': test_rec,\n",
    "                'F1_Score': test_f1\n",
    "            }\n",
    "            # torch.save(model.state_dict(), f\"/home/user/Downloads/moment/models/best_moment_{appliance}.pth\")\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"✅ Finished {appliance} in {elapsed:.2f} seconds.\")\n",
    "\n",
    "    results.append(final_metrics)\n",
    "\n",
    "# Save results as CSV\n",
    "results_df1 = pd.DataFrame(results)\n",
    "results_df1.insert(1, 'Freq', 60)  # Add frequency column\n",
    "results_df1\n",
    "# results_df.to_csv(\"/home/user/Downloads/moment/Classification_results/comstock_60min_fine_tune_results_try.csv\", index=False)\n",
    "# print(\"\\n All appliance-wise results saved as CSV!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00724dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from momentfm import MOMENTPipeline\n",
    "from momentfm.data.classification_dataset import ClassificationDataset\n",
    "from aeon.datasets import write_to_ts_file\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "df = pd.read_csv(\"./Dataset/Classification/60_min/comstock_60min_small.csv\").drop(\"Timestamp\", axis=1)\n",
    "X = df.T  \n",
    "df_label_all = pd.read_csv(\"./Dataset/Classification/60_min/comstock_60min_labels.csv\")\n",
    "appliance_names = ['cooling_ON', 'fans_ON', 'heat_rejection_ON', 'heating_ON', 'refrigeration_ON', 'water_systems_ON']\n",
    "df_label = df_label_all[appliance_names]\n",
    "y = df_label.values  \n",
    "Num_time_series = 700\n",
    "length_time_series = 168\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "results = []  # Store results per appliance\n",
    "\n",
    "for appliance in appliance_names:\n",
    "    print(f\"\\n⚡ Starting fine-tuning for appliance: {appliance}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Get the data for the current appliance\n",
    "    y = df_label_all[appliance]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "    X_train = np.array(X_train)[:, np.newaxis, :]\n",
    "    X_test = np.array(X_test)[:, np.newaxis, :]\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    # Save data as .ts files\n",
    "    write_to_ts_file(X_train, '/home/user/Downloads/moment/dataset/', y_train, problem_name='Comstock_TRAIN.ts', header=None, regression=False)\n",
    "    write_to_ts_file(X_test, '/home/user/Downloads/moment/dataset/', y_test, problem_name='Comstock_TEST.ts', header=None, regression=False)\n",
    "\n",
    "    train_dataset = ClassificationDataset(data_split='train')\n",
    "    test_dataset = ClassificationDataset(data_split='test')\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "    model = MOMENTPipeline.from_pretrained(\n",
    "        \"AutonLab/MOMENT-1-large\", \n",
    "        model_kwargs={\n",
    "            'task_name': 'classification',\n",
    "            'n_channels': 1,\n",
    "            'num_class': 2,\n",
    "            'freeze_encoder': False,\n",
    "            'freeze_embedder': False,\n",
    "            'reduction': 'mean',\n",
    "        },\n",
    "    )\n",
    "    model.init()\n",
    "    model.to(device).float()\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    T_MAX = max(int((Num_time_series / length_time_series) / batch_size * epochs), 1)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=T_MAX, eta_min=1e-7)\n",
    "\n",
    "    best_test_acc = 0.0\n",
    "    final_metrics = {}\n",
    "\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        for batch_x, batch_masks, batch_labels in tqdm(train_loader):\n",
    "            batch_x = batch_x.to(device).float().requires_grad_()\n",
    "            batch_masks = batch_masks.to(device).long()\n",
    "            batch_labels = batch_labels.to(device).long()\n",
    "            batch_masks = torch.ones(batch_x.size(0), batch_x.size(-1)).long().to(device)\n",
    "\n",
    "            output = model(x_enc=batch_x, input_mask=batch_masks, reduction='mean')\n",
    "            logits = output.logits\n",
    "\n",
    "            loss = criterion(logits, batch_labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=5.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            correct_preds += (predicted == batch_labels).sum().item()\n",
    "            total_preds += batch_labels.size(0)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        correct_test_preds = 0\n",
    "        total_test_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_masks, batch_labels in test_loader:\n",
    "                batch_x = batch_x.to(device).float()\n",
    "                batch_masks = batch_masks.to(device).long()\n",
    "                batch_labels = batch_labels.to(device).long()\n",
    "\n",
    "                output = model(x_enc=batch_x, input_mask=batch_masks, reduction='mean')\n",
    "                logits = output.logits\n",
    "\n",
    "                _, predicted = torch.max(logits, 1)\n",
    "                correct_test_preds += (predicted == batch_labels).sum().item()\n",
    "                total_test_preds += batch_labels.size(0)\n",
    "\n",
    "                all_preds.append(predicted.cpu().numpy())\n",
    "                all_labels.append(batch_labels.cpu().numpy())\n",
    "\n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        all_labels = np.concatenate(all_labels)\n",
    "\n",
    "        test_acc = correct_test_preds / total_test_preds\n",
    "        test_prec = precision_score(all_labels, all_preds, zero_division=1)\n",
    "        test_rec = recall_score(all_labels, all_preds, zero_division=1)\n",
    "        test_f1 = f1_score(all_labels, all_preds, zero_division=1, average='macro')\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Test Acc={test_acc:.4f}, Precision={test_prec:.4f}, Recall={test_rec:.4f}, F1={test_f1:.4f}\")\n",
    "\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            final_metrics = {\n",
    "                'Appliance': appliance,\n",
    "                'Accuracy': test_acc,\n",
    "                'Precision': test_prec,\n",
    "                'Recall': test_rec,\n",
    "                'F1_Score': test_f1\n",
    "            }\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"✅ Finished {appliance} in {elapsed:.2f} seconds.\")\n",
    "\n",
    "    results.append(final_metrics)\n",
    "\n",
    "results_df1 = pd.DataFrame(results)\n",
    "print(f\"\\nAll appliance-wise results saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "momentfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
