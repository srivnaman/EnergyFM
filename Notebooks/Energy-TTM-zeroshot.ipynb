{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš¡ Zero-Shot Forecasting with EnergyTTM\n",
    "\n",
    "This notebook performs **zero-shot energy forecasting** using a pretrained EnergyTTM model without task-specific fine-tuning.\n",
    "\n",
    "The workflow includes:\n",
    "- Loading pretrained model weights\n",
    "- Preparing time-series energy data\n",
    "- Running forward inference for forecasting\n",
    "- Evaluating predictions using standard metrics\n",
    "\n",
    "The objective is to assess the generalization capability of EnergyTTM on unseen buildings in a zero-shot setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Let's import the required libraries and initializes the environment for training and evaluating TinyTimeMixer models.\n",
    "\n",
    "It includes:\n",
    "- Core Python utilities and reproducibility setup (seed control)\n",
    "- PyTorch modules for model training\n",
    "- HuggingFace Trainer utilities\n",
    "- Time-series preprocessing and dataset loaders\n",
    "- Evaluation metrics and visualization tools\n",
    "\n",
    "The environment is configured for deterministic execution with a fixed random seed to ensure reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random \n",
    "import math \n",
    "import tempfile \n",
    "import torch \n",
    "import pickle \n",
    "import logging \n",
    "import warnings\n",
    "import json\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from transformers import Trainer, TrainingArguments, set_seed, EarlyStoppingCallback\n",
    "from torch.utils.data import ConcatDataset, Dataset, DataLoader\n",
    "\n",
    "\n",
    "from tsfm_public.models.tinytimemixer.configuration_tinytimemixer import TinyTimeMixerConfig\n",
    "from tsfm_public.models.tinytimemixer import TinyTimeMixerForPrediction\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED = 42\n",
    "set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "This section defines the performance metrics used to evaluate forecasting quality.\n",
    "\n",
    "The following metrics are computed:\n",
    "\n",
    "- **CVRMSE (Coefficient of Variation of RMSE)**  \n",
    "  Measures normalized root mean squared error relative to the mean of the true values.  \n",
    "  Useful for energy forecasting benchmarks where scale normalization is required.\n",
    "\n",
    "- **MAE (Mean Absolute Error)**  \n",
    "  Computes the average absolute difference between predictions and ground truth.  \n",
    "  Provides an interpretable measure of average forecast deviation.\n",
    "\n",
    "- **NRMSE (Normalized RMSE, %)**  \n",
    "  Root mean squared error normalized by the mean load and expressed as a percentage.  \n",
    "  Particularly suitable for daily energy series (24-hour structure assumed).\n",
    "\n",
    "These metrics together evaluate both absolute and scale-normalized forecasting performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# metrics used for evaluation\n",
    "def cal_cvrmse(pred, true, eps=1e-8):\n",
    "    pred = np.array(pred)\n",
    "    true = np.array(true)\n",
    "    return np.power(np.square(pred - true).sum() / pred.shape[0], 0.5) / (true.sum() / pred.shape[0] + eps)\n",
    "\n",
    "def cal_mae(pred, true):\n",
    "    pred = np.array(pred)\n",
    "    true = np.array(true)\n",
    "    return np.mean(np.abs(pred - true))\n",
    "\n",
    "def cal_nrmse(pred, true, eps=1e-8):\n",
    "    true = np.array(true)\n",
    "    pred = np.array(pred)\n",
    "\n",
    "    M = len(true) // 24\n",
    "    y_bar = np.mean(true)\n",
    "    NRMSE = 100 * (1/ (y_bar+eps)) * np.sqrt((1 / (24 * M)) * np.sum((true - pred) ** 2))\n",
    "    return NRMSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-Series Dataset & Scaling\n",
    "\n",
    "This section defines preprocessing and dataset utilities for supervised forecasting.\n",
    "\n",
    "### ğŸ”¹ Standardization\n",
    "- The time series is normalized using z-score scaling:\n",
    "  $\n",
    "  x' = \\frac{x - \\mu}{\\sigma}\n",
    "  $\n",
    "- Mean and standard deviation are stored to later **unscale predictions** back to the original energy units.\n",
    "\n",
    "### ğŸ”¹ Sliding Window Dataset\n",
    "`TimeSeriesDataset` constructs supervised training samples using a rolling window approach:\n",
    "\n",
    "- **Backcast length** â†’ historical input window  \n",
    "- **Forecast length** â†’ prediction horizon  \n",
    "- **Stride** â†’ step size between consecutive windows  \n",
    "\n",
    "Each sample returns:\n",
    "- `x` â†’ past sequence (input)\n",
    "- `y` â†’ future sequence (target)\n",
    "\n",
    "This enables efficient training for sequence-to-sequence forecasting models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def standardize_series(series, eps=1e-8):\n",
    "    mean = np.mean(series)\n",
    "    std = np.std(series)\n",
    "    standardized_series = (series - mean) / (std+eps)\n",
    "    return standardized_series, mean, std\n",
    "\n",
    "def unscale_predictions(predictions, mean, std, eps=1e-8):\n",
    "    return predictions * (std+eps) + mean\n",
    "\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, backcast_length, forecast_length, stride=1):\n",
    "        # Standardize the time series data\n",
    "        self.data, self.mean, self.std = standardize_series(data)\n",
    "        self.backcast_length = backcast_length\n",
    "        self.forecast_length = forecast_length\n",
    "        self.stride = stride\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.data) - self.backcast_length - self.forecast_length) // self.stride + 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start_index = index * self.stride\n",
    "        x = self.data[start_index : start_index + self.backcast_length]\n",
    "        y = self.data[start_index + self.backcast_length : start_index + self.backcast_length + self.forecast_length]\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the TinyTimeMixer Model\n",
    "\n",
    "Here, we initialize the **TinyTimeMixer forecasting model** using a structured configuration dictionary.\n",
    "\n",
    "### ğŸ”¹ What We Do\n",
    "- Create a `TinyTimeMixerConfig` from the provided `args`\n",
    "- Set architectural and training parameters (context length, prediction length, layers, attention, patching, decoder options, etc.)\n",
    "- Instantiate `TinyTimeMixerForPrediction` with this configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_config(args):\n",
    "\n",
    "    config = TinyTimeMixerConfig(\n",
    "        context_length=args[\"context_length\"],\n",
    "        patch_length=args[\"patch_length\"],\n",
    "        num_input_channels=args[\"num_input_channels\"],\n",
    "        patch_stride=args[\"patch_stride\"],\n",
    "        d_model=args[\"d_model\"],\n",
    "        num_layers=args[\"num_layers\"],\n",
    "        expansion_factor=args[\"expansion_factor\"],\n",
    "        dropout=args[\"dropout\"],\n",
    "        head_dropout=args[\"head_dropout\"],\n",
    "        mode=args[\"mode\"][0],\n",
    "        scaling=args[\"scaling\"],\n",
    "        prediction_length=args[\"prediction_length\"],\n",
    "        is_scaling=args[\"is_scaling\"],\n",
    "        gated_attn=args[\"gated_attn\"],\n",
    "        norm_mlp=args[\"norm_mlp\"],\n",
    "        self_attn=args[\"self_attn\"],\n",
    "        self_attn_heads=args[\"self_attn_heads\"],\n",
    "        use_positional_encoding=args[\"use_positional_encoding\"],\n",
    "        positional_encoding_type=args[\"positional_encoding_type\"],\n",
    "        loss=args[\"loss\"],\n",
    "        init_std=args[\"init_std\"],\n",
    "        post_init=args[\"post_init\"],\n",
    "        norm_eps=args[\"norm_eps\"],\n",
    "        adaptive_patching_levels=args[\"adaptive_patching_levels\"],\n",
    "        resolution_prefix_tuning=args[\"resolution_prefix_tuning\"],\n",
    "        frequency_token_vocab_size=args[\"frequency_token_vocab_size\"],\n",
    "        distribution_output=args[\"distribution_output\"],\n",
    "        num_parallel_samples=args[\"num_parallel_samples\"],\n",
    "        decoder_num_layers=args[\"decoder_num_layers\"],\n",
    "        decoder_d_model=args[\"decoder_d_model\"],\n",
    "        decoder_adaptive_patching_levels=args[\"decoder_adaptive_patching_levels\"],\n",
    "        decoder_raw_residual=args[\"decoder_raw_residual\"],\n",
    "        decoder_mode=args[\"decoder_mode\"],\n",
    "        use_decoder=args[\"use_decoder\"],\n",
    "        enable_forecast_channel_mixing=args[\"enable_forecast_channel_mixing\"],\n",
    "        fcm_gated_attn=args[\"fcm_gated_attn\"],\n",
    "        fcm_context_length=args[\"fcm_context_length\"],\n",
    "        fcm_use_mixer=args[\"fcm_use_mixer\"],\n",
    "        fcm_mix_layers=args[\"fcm_mix_layers\"],\n",
    "        fcm_prepend_past=args[\"fcm_prepend_past\"], \n",
    "        init_linear=args[\"init_linear\"],\n",
    "        init_embed=args[\"init_embed\"],\n",
    "\n",
    "    )\n",
    "\n",
    "    pretraining_model = TinyTimeMixerForPrediction(config)\n",
    "    return pretraining_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ› ï¸ Helper Functions for the Evaluation Pipeline\n",
    "\n",
    "These helper functions modularize the testing workflow to improve readability, reusability, and debugging. They handle building selection, data cleaning, dataset preparation, inference, and metric computation in clearly separated steps. This structured design keeps the main evaluation loop clean and maintainable.\n",
    "\n",
    "- **Building Selection** â€“ Identify which building columns to evaluate (`\"all\"`, single, or multiple).\n",
    "- **Data Cleaning** â€“ Replace missing values using median imputation.\n",
    "- **Dataset Validation** â€“ Ensure sufficient sequence length and construct sliding-window samples.\n",
    "- **Inference Execution** â€“ Run model forward passes and collect predictions.\n",
    "- **Metric Evaluation** â€“ Unscale outputs and compute CVRMSE, NRMSE, and MAE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_buildings_to_test(df, target_buildings):\n",
    "    if target_buildings == \"all\":\n",
    "        return list(df.columns)\n",
    "    elif isinstance(target_buildings, str):\n",
    "        return [target_buildings]\n",
    "    elif isinstance(target_buildings, list):\n",
    "        return target_buildings\n",
    "    else:\n",
    "        raise ValueError(\"target_buildings must be 'all', a string, or list\")\n",
    "\n",
    "\n",
    "def clean_series(energy_data):\n",
    "    nan_count = np.isnan(energy_data).sum()\n",
    "    if nan_count > 0:\n",
    "        median_val = np.nanmedian(energy_data)\n",
    "        energy_data = np.where(np.isnan(energy_data), median_val, energy_data)\n",
    "        print(f\"  Filled {nan_count} NaNs with median={median_val:.4f}\")\n",
    "    return energy_data\n",
    "\n",
    "\n",
    "def create_dataset_if_valid(energy_data, args):\n",
    "    min_required = args[\"context_length\"] + args[\"prediction_length\"]\n",
    "\n",
    "    if len(energy_data) < min_required:\n",
    "        print(\"   Too short, skipping...\")\n",
    "        return None\n",
    "\n",
    "    dataset = TimeSeriesDataset(\n",
    "        energy_data,\n",
    "        args[\"context_length\"],\n",
    "        args[\"prediction_length\"],\n",
    "        args[\"patch_stride\"]\n",
    "    )\n",
    "\n",
    "    if len(dataset) == 0:\n",
    "        print(\"   No samples, skipping...\")\n",
    "        return None\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def run_inference(model, dataset, criterion, device):\n",
    "    model.eval()\n",
    "\n",
    "    val_losses = []\n",
    "    y_true_test = []\n",
    "    y_pred_test = []\n",
    "\n",
    "    for x_test, y_test in DataLoader(dataset, batch_size=1):\n",
    "        x_test = x_test.unsqueeze(-1).to(device)\n",
    "        y_test = y_test.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(x_test)\n",
    "            forecast = output.prediction_outputs.squeeze(-1)\n",
    "\n",
    "            loss = criterion(forecast, y_test)\n",
    "            if torch.isnan(loss):\n",
    "                continue\n",
    "\n",
    "            val_losses.append(loss.item())\n",
    "            y_true_test.append(y_test.cpu().numpy())\n",
    "            y_pred_test.append(forecast.cpu().numpy())\n",
    "\n",
    "    if len(y_true_test) == 0:\n",
    "        return None\n",
    "\n",
    "    y_true = np.concatenate(y_true_test, axis=0)\n",
    "    y_pred = np.concatenate(y_pred_test, axis=0)\n",
    "\n",
    "    return y_true, y_pred, np.mean(val_losses)\n",
    "\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred, dataset):\n",
    "    y_pred_unscaled = unscale_predictions(y_pred, dataset.mean, dataset.std)\n",
    "    y_true_unscaled = unscale_predictions(y_true, dataset.mean, dataset.std)\n",
    "\n",
    "    cvrmse = cal_cvrmse(y_pred_unscaled, y_true_unscaled)\n",
    "    nrmse  = cal_nrmse(y_pred_unscaled, y_true_unscaled)\n",
    "    mae    = cal_mae(y_pred_unscaled, y_true_unscaled)\n",
    "\n",
    "    return cvrmse, nrmse, mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(args, model, criterion, dataset_path, result_path, device, target_buildings=\"BR02\"):\n",
    "\n",
    "    os.makedirs(result_path, exist_ok=True)\n",
    "    res = []\n",
    "\n",
    "    for file_name in os.listdir(dataset_path):\n",
    "\n",
    "        if not file_name.endswith(\".parquet\"):\n",
    "            continue\n",
    "\n",
    "        file_id = file_name.replace(\".parquet\", \"\")\n",
    "        file_path = os.path.join(dataset_path, file_name)\n",
    "\n",
    "        print(f\"\\nTesting file: {file_id}\")\n",
    "\n",
    "        df = pd.read_parquet(file_path)\n",
    "        buildings_to_test = get_buildings_to_test(df, target_buildings)\n",
    "\n",
    "        for building_col in buildings_to_test:\n",
    "\n",
    "            if building_col not in df.columns:\n",
    "                print(f\" {building_col} not found, skipping...\")\n",
    "                continue\n",
    "\n",
    "            print(f\"   â–¶ Building: {building_col}\")\n",
    "\n",
    "            energy_data = df[building_col].values.astype(np.float32)\n",
    "            energy_data = clean_series(energy_data)\n",
    "\n",
    "            dataset = create_dataset_if_valid(energy_data, args)\n",
    "            if dataset is None:\n",
    "                continue\n",
    "\n",
    "            inference_output = run_inference(model, dataset, criterion, device)\n",
    "            if inference_output is None:\n",
    "                print(\"   No predictions collected, skipping...\")\n",
    "                continue\n",
    "\n",
    "            y_true, y_pred, avg_loss = inference_output\n",
    "            cvrmse, nrmse, mae = evaluate_predictions(y_true, y_pred, dataset)\n",
    "\n",
    "            print(f\"   CVRMSE={cvrmse:.4f}, NRMSE={nrmse:.4f}, MAE={mae:.4f}\")\n",
    "\n",
    "            res.append([file_id, building_col, cvrmse, nrmse, mae, avg_loss])\n",
    "\n",
    "    columns = [\"Dataset\", \"Building\", \"CVRMSE\", \"NRMSE\", \"MAE\", \"Avg_Test_Loss\"]\n",
    "    result_df = pd.DataFrame(res, columns=columns)\n",
    "\n",
    "    result_csv = os.path.join(result_path, \"test_results.csv\")\n",
    "    result_df.to_csv(result_csv, index=False)\n",
    "\n",
    "    print(\"\\nTesting complete!\")\n",
    "    print(\"Results saved at:\", result_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:p-2079666:t-139244917499712:modeling_tinytimemixer.py:__init__:Disabling adaptive patching at level 2. Either increase d_model or reduce adaptive_patching_levels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's parameter count is: 28858\n",
      "\n",
      "Testing file: Bareilly-1H\n",
      "   â–¶ Building: BR02\n",
      "  Filled 9984 NaNs with median=0.1660\n",
      "   CVRMSE=0.0974, NRMSE=236.3778, MAE=0.0428\n",
      "\n",
      "Testing file: Mathura-1H\n",
      " BR02 not found, skipping...\n",
      "\n",
      "Testing complete!\n",
      "Results saved at: test_results_zeroshot/test_results.csv\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------\n",
    "# Load Model Configuration\n",
    "# -------------------------------------------------------\n",
    "config_file = '../Energy-TTM/config/tinyTimeMixers.json'\n",
    "\n",
    "# Read hyperparameters from JSON config\n",
    "with open(config_file, 'r') as f:\n",
    "    args = json.load(f)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Device Setup (GPU if available, else CPU)\n",
    "# -------------------------------------------------------\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Initialize Model\n",
    "# -------------------------------------------------------\n",
    "# Build TinyTimeMixer model from configuration\n",
    "model = model_config(args).to(device)\n",
    "\n",
    "# Load pretrained Energy-TTM weights (zero-shot setup)\n",
    "model.load_state_dict(torch.load('../Energy-TTM/Weights/energy_ttm.pth'))\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Model Statistics\n",
    "# -------------------------------------------------------\n",
    "# Count trainable parameters\n",
    "param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Model's parameter count is:\", param)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Define Loss Function\n",
    "# -------------------------------------------------------\n",
    "# Mean Squared Error for forecasting evaluation\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Run Zero-Shot Testing\n",
    "# -------------------------------------------------------\n",
    "# Evaluate pretrained model on forecasting dataset\n",
    "test(\n",
    "    args=args,\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    dataset_path=\"../Dataset/Forecasting\",\n",
    "    result_path=\"test_results_zeroshot\",\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energy-ttm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
